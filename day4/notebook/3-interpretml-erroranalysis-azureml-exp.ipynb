{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## LightGBM 分類モデルの SHAP による説明と Error Analysis + Azure ML\n",
    "LightGBM で構築した年収予測 (50kドル以上か以下かを予測する分類問題)のモデルを Interpret-community の SHAPベースの explainer を用いて説明 (グローバル、ローカル) を行います。また  [Error Analysis](https://erroranalysis.ai/) を用いてモデルの誤差が大きいコホートを抽出します。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. 事前準備\n",
    "- Jupyter Kernel :  `rai-aml` を選択する。\n",
    "    - [0-Setup.ipynb](./0-Setup.ipynb) の手順に従い構築しておくこと。\n",
    "\n",
    "\n",
    "- Azure ML Dataset : `adult_census` を利用するため登録済みか確認する。\n",
    "    - [0-Setup.ipynb](./0-Setup.ipynb) の手順に従い登録しておくこと。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. ライブラリ\n",
    "必要な Python ライブラリをインポートします。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Run, Experiment, Workspace, Model, Dataset\n",
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from raiwidgets import ExplanationDashboard\n",
    "\n",
    "import joblib\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1614575324617
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# interpret-community 関連\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "from interpret_community.common.constants import ModelTask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Azure ML Workspace 設定\n",
    "Azure Machine Learning Workspace と接続します。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ws = Workspace.from_config()"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1614575326335
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. データ準備\n",
    "adult census の Dataset を呼び出し Pandas DataFrame に変換します。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = Dataset.get_by_name(ws, name='adult_census').to_pandas_dataframe().sample(1000, random_state=1234)\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1614575330369
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 簡単のため race=Other のデータを除去する\n",
    "df_raw = df[df.race!='Other']"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1614575330685
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 説明変数と目的変数に分離\n",
    "X = df_raw.drop(['target'], axis=1)\n",
    "Y = df_raw['target']\n",
    "Y = (Y == '>50K') * 1"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1614575330811
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 学習データとテストデータに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 学習パイプライン"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Azure ML 実験の設定"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp = Experiment(ws, \"rai-explain-erroranalysis\")\n",
    "run = exp.start_logging(snapshot_directory=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LightGBM パラメータ設定"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## LightGBM Parameter list (https://lightgbm.readthedocs.io/en/latest/Parameters.html)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators':1000,\n",
    "    'metric': 'auc',\n",
    "    'colsample_bytree': 1.0,\n",
    "    'reg_alpha': 1e-3,\n",
    "    'reg_lambda': 1e-3,\n",
    "    'seed': 1234,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params_fit = {\n",
    "              \"classifier__verbose\":10, \n",
    "             }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### scikit learn pipeline 構築"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features = X.columns.values.tolist()\n",
    "classes = ['<=50K' ,'>50K']\n",
    "feat_list = {\n",
    "'num_cols': X.dtypes[X.dtypes == 'float64'].index.values.tolist(),\n",
    "'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "}\n",
    "print(feat_list)\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),\n",
    "    ('num_scaler', StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "feat_pipe = ColumnTransformer([\n",
    "    ('num_pipe', num_pipe, feat_list['num_cols']),\n",
    "    ('cat_pipe', cat_pipe, feat_list['cat_cols'])\n",
    "])\n",
    "\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", feat_pipe),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LGBMClassifier(**params),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. モデル学習"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# scikit learn パイプラインの実行\n",
    "model.fit(X_train, y_train, **params_fit);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "モデルの精度を確認し、メトリックとして記録します。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.log('train AUC',roc_auc_score(y_train, model.predict(X_train)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.log('test AUC',roc_auc_score(y_test, model.predict(X_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. モデル説明 (SHAP Tabular Explainer)\n",
    "interpret-community の `TabularExplainer` を用いて explainer を生成します。TabularExplainer は最適な [SHAP Explainer](https://github.com/interpretml/interpret-community#supported-explainers) を自動で選択します。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "explainer = TabularExplainer(model.steps[-1][1],\n",
    "                             initialization_examples=X_train, # データの母集団を引数に渡す。テストデータ X_test でも可。\n",
    "                             features=features,\n",
    "                             classes=classes,\n",
    "                             transformations=feat_pipe,\n",
    "                             model_task = ModelTask.Classification)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "global_explanation = explainer.explain_global(X_train)\n",
    "local_explanation = explainer.explain_local(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client = ExplanationClient.from_run(run)\n",
    "client.upload_model_explanation(global_explanation, \n",
    "                                comment='global explanation', \n",
    "                                true_ys=y_train.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from raiwidgets import ExplanationDashboard\n",
    "ExplanationDashboard(global_explanation, model, dataset=X_train, true_y=y_train.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# テストデータ\n",
    "client.upload_model_explanation(local_explanation, \n",
    "                                comment='local explanation',\n",
    "                                true_ys=y_test.values\n",
    "                               )\n",
    "ExplanationDashboard(local_explanation, model, dataset=X_test, true_y=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. モデル誤差分析 (Error Analysis)\n",
    "[Error Analysis](https://erroranalysis.ai/) を用いてモデルの誤差を分析し、特に誤差が大きいコホートを特定します。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from raiwidgets import ErrorAnalysisDashboard"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ErrorAnalysisDashboard(global_explanation, model,\n",
    "#                        dataset=X_train, \n",
    "#                        true_y=y_train.values, \n",
    "#                        categorical_features=feat_list['cat_cols'],\n",
    "#                       )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ErrorAnalysisDashboard(local_explanation, model,\n",
    "                       dataset=X_test, \n",
    "                       true_y=y_test.to_numpy(),\n",
    "                       model_task=\"classification\",\n",
    "                       categorical_features=feat_list['cat_cols'],\n",
    "                       true_y_dataset=y_test.to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 実験環境\n",
    "run.complete()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rai-aml",
   "language": "python",
   "name": "rai-aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}